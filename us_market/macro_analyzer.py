#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Macro Market Analyzer
- Collects macro indicators (VIX, Yields, Commodities, etc.)
- Uses Gemini AI to generate investment strategy
"""

import os
import sys
import json
import requests
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import pandas as pd
from pathlib import Path
from dotenv import load_dotenv

BASE_DIR = Path(__file__).resolve().parents[1]
if str(BASE_DIR) not in sys.path:
    sys.path.append(str(BASE_DIR))

from utils.fmp_client import get_fmp_client

# Load .env
load_dotenv()
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class MacroDataCollector:
    """Collect macro market data from various sources"""
    
    def __init__(self):
        self.macro_tickers = {
            'VIX': '^VIX',
            'DXY': 'DX-Y.NYB',
            'GOLD': 'GC=F',
            'OIL': 'CL=F',
            'BTC': 'BTC-USD',
            'SPY': 'SPY',
            'QQQ': 'QQQ'
        }
        self.client = get_fmp_client()

    def _fetch_52w_range(self, symbol: str) -> Dict[str, float]:
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=370)
        payload = self.client.historical_price_full(
            symbol,
            from_date=start_date.strftime("%Y-%m-%d"),
            to_date=end_date.strftime("%Y-%m-%d"),
        )
        hist = pd.DataFrame(payload.get("historical") or [])
        if hist.empty:
            return {"high": 0.0, "low": 0.0, "pct_from_high": 0.0}
        high = float(hist["high"].max()) if "high" in hist.columns else 0.0
        low = float(hist["low"].min()) if "low" in hist.columns else 0.0
        return {"high": high, "low": low}
    
    def get_current_macro_data(self) -> Dict:
        """Fetch current macro indicators"""
        logger.info("ğŸ“Š Fetching macro data...")
        macro_data = {}
        
        try:
            tickers = list(self.macro_tickers.values())
            quotes = self.client.quote(tickers)
            quote_map = {q.get("symbol"): q for q in quotes if isinstance(q, dict)}

            for name, ticker in self.macro_tickers.items():
                try:
                    mapped = map_symbol(ticker)
                    quote = quote_map.get(mapped)
                    if not quote:
                        continue
                    val = quote.get("price")
                    prev = quote.get("previousClose") or val
                    if val is None:
                        continue
                    change = ((float(val) / float(prev)) - 1) * 100 if prev else 0

                    range_52w = self._fetch_52w_range(ticker)
                    high = range_52w.get("high", val) or val
                    low = range_52w.get("low", val) or val
                    pct_high = ((float(val) / float(high)) - 1) * 100 if high else 0

                    macro_data[name] = {
                        'value': round(float(val), 2),
                        'change_1d': round(float(change), 2),
                        'pct_from_high': round(float(pct_high), 1),
                        '52w_high': round(float(high), 2),
                        '52w_low': round(float(low), 2)
                    }
                except Exception as e:
                    logger.debug(f"Error processing {name}: {e}")
                    continue

            # Treasury yields
            try:
                rates = self.client.treasury_rates()
                if rates:
                    latest = rates[0]
                    prev = rates[1] if len(rates) > 1 else latest
                    for label, key in (("2Y_Yield", "2Y"), ("10Y_Yield", "10Y")):
                        if latest.get(key) is None:
                            continue
                        cur = float(latest.get(key))
                        prev_val = prev.get(key) if prev else None
                        prev_val = float(prev_val) if prev_val is not None else cur
                        change = ((cur / prev_val) - 1) * 100 if prev_val else 0
                        macro_data[label] = {
                            "value": round(cur, 2),
                            "change_1d": round(change, 2),
                            "pct_from_high": 0,
                            "52w_high": cur,
                            "52w_low": cur,
                        }
            except Exception:
                pass
            
            # Yield Spread (10Y - 2Y)
            if '2Y_Yield' in macro_data and '10Y_Yield' in macro_data:
                spread = macro_data['10Y_Yield']['value'] - macro_data['2Y_Yield']['value']
                macro_data['YieldSpread'] = {
                    'value': round(spread, 2),
                    'change_1d': 0,
                    'pct_from_high': 0,
                    'interpretation': 'Normal' if spread > 0 else 'Inverted (Recession Warning)'
                }
            
            # Fear & Greed (placeholder - would need CNN API)
            if 'VIX' in macro_data:
                vix = macro_data['VIX']['value']
                if vix > 30:
                    fg_score = 25  # Fear
                    fg_label = "Extreme Fear"
                elif vix > 20:
                    fg_score = 40
                    fg_label = "Fear"
                elif vix > 15:
                    fg_score = 55
                    fg_label = "Neutral"
                else:
                    fg_score = 75
                    fg_label = "Greed"
                    
                macro_data['FearGreed'] = {
                    'value': fg_score,
                    'label': fg_label,
                    'change_1d': 0
                }
                
        except Exception as e:
            logger.error(f"Error fetching macro data: {e}")
            
        return macro_data

    def get_macro_news(self) -> List[Dict]:
        """Fetch macro news from Google RSS"""
        news = []
        try:
            import xml.etree.ElementTree as ET
            
            url = "https://news.google.com/rss/search?q=Federal+Reserve+Economy&hl=en-US&gl=US&ceid=US:en"
            resp = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
            
            if resp.status_code == 200:
                root = ET.fromstring(resp.content)
                for item in root.findall('.//item')[:5]:
                    title = item.find('title')
                    pub_date = item.find('pubDate')
                    news.append({
                        'title': title.text if title is not None else 'No title',
                        'published': pub_date.text if pub_date is not None else '',
                        'source': 'Google News'
                    })
        except Exception as e:
            logger.debug(f"Error fetching news: {e}")
            
        return news
        
    def get_historical_patterns(self) -> List[Dict]:
        """Get historical market patterns for context"""
        return [
            {
                'event': 'Fed Pivot Signal (2023)',
                'conditions': 'VIX declining, Yields peaking',
                'outcome': {'SPY_3m': '+15%', 'best_sectors': ['Tech', 'Communications']}
            },
            {
                'event': 'Inflation Peak (2022)',
                'conditions': 'CPI declining, Fed pause',
                'outcome': {'SPY_3m': '+8%', 'best_sectors': ['Growth', 'Consumer Discretionary']}
            }
        ]


class MacroAIAnalyzer:
    """Gemini AI Analysis for Macro Data"""
    
    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
        self.url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def analyze(self, data: Dict, news: List, patterns: List, lang: str = 'ko') -> str:
        """Generate AI analysis"""
        if not self.api_key:
            return "âš ï¸ GOOGLE_API_KEY not set. Please add it to .env file."
        
        prompt = self._build_prompt(data, news, patterns, lang)
        
        try:
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"temperature": 0.7, "maxOutputTokens": 2000}
            }
            resp = requests.post(
                f"{self.url}?key={self.api_key}",
                json=payload,
                timeout=30
            )
            
            if resp.status_code == 200:
                result = resp.json()
                return result['candidates'][0]['content']['parts'][0]['text']
            else:
                return f"API Error: {resp.status_code} - {resp.text[:200]}"
                
        except Exception as e:
            return f"Error generating analysis: {e}"
    
    def _build_prompt(self, data: Dict, news: List, patterns: List, lang: str) -> str:
        """Build analysis prompt"""
        # Format metrics
        metrics_lines = []
        for k, v in data.items():
            if isinstance(v, dict):
                val = v.get('value', 'N/A')
                chg = v.get('change_1d', 0)
                metrics_lines.append(f"- {k}: {val} ({chg:+.2f}%)")
            else:
                metrics_lines.append(f"- {k}: {v}")
        metrics = "\n".join(metrics_lines)
        
        # Format headlines
        headlines = "\n".join([n['title'] for n in news[:5]])
        
        if lang == 'en':
            return f"""You are a professional macro market analyst. Analyze current conditions and provide investment strategy.

## Current Macro Indicators:
{metrics}

## Recent News:
{headlines}

## Request:
Provide a concise analysis covering:
1. **Market Summary** (2-3 sentences)
2. **Key Opportunities** (sectors/assets to favor)
3. **Key Risks** (what to watch)
4. **Recommended Strategy** (specific actionable advice)

Be direct and professional. No emojis."""
        else:
            return f"""ë‹¹ì‹ ì€ ì „ë¬¸ ë§¤í¬ë¡œ ì‹œì¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ìƒí™©ì„ ë¶„ì„í•˜ê³  íˆ¬ì ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”.

## í˜„ì¬ ë§¤í¬ë¡œ ì§€í‘œ:
{metrics}

## ìµœê·¼ ë‰´ìŠ¤:
{headlines}

## ìš”ì²­:
ë‹¤ìŒì„ í¬í•¨í•œ ê°„ê²°í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”:
1. **ì‹œì¥ ìš”ì•½** (2-3ë¬¸ì¥)
2. **ê¸°íšŒ ìš”ì¸** (ì£¼ëª©í•  ì„¹í„°/ìì‚°)
3. **ë¦¬ìŠ¤í¬ ìš”ì¸** (ì£¼ì˜í•  ì )
4. **ì¶”ì²œ ì „ëµ** (êµ¬ì²´ì  ì¡°ì–¸)

ì „ë¬¸ì ì´ê³  ì§ì ‘ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì´ëª¨ì§€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""


class MultiModelAnalyzer:
    """Main analyzer combining data collection and AI analysis"""
    
    def __init__(self, data_dir: str = '.'):
        self.data_dir = data_dir
        self.collector = MacroDataCollector()
        self.gemini = MacroAIAnalyzer()
        self.output_file = os.path.join(data_dir, 'macro_analysis.json')
    
    def run(self) -> Dict:
        """Run full macro analysis"""
        logger.info("ğŸš€ Starting Macro Market Analysis...")
        
        # Collect data
        data = self.collector.get_current_macro_data()
        news = self.collector.get_macro_news()
        patterns = self.collector.get_historical_patterns()
        
        logger.info(f"ğŸ“Š Collected {len(data)} indicators, {len(news)} news items")
        
        # AI Analysis
        logger.info("ğŸ¤– Generating AI analysis...")
        analysis_ko = self.gemini.analyze(data, news, patterns, 'ko')
        analysis_en = self.gemini.analyze(data, news, patterns, 'en')
        
        # Build output
        output = {
            'timestamp': datetime.now().isoformat(),
            'macro_indicators': data,
            'news': news,
            'historical_patterns': patterns,
            'ai_analysis': {
                'ko': analysis_ko,
                'en': analysis_en
            }
        }
        
        # Save Korean version
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… Saved to {self.output_file}")
        
        # Save English version
        en_output_file = os.path.join(self.data_dir, 'macro_analysis_en.json')
        en_output = {
            'timestamp': output['timestamp'],
            'macro_indicators': data,
            'ai_analysis': analysis_en
        }
        with open(en_output_file, 'w') as f:
            json.dump(en_output, f, indent=2)
        
        return output
    
    def print_summary(self, output: Dict):
        """Print analysis summary"""
        print("\nğŸ“Š Macro Market Summary")
        print("=" * 50)
        
        data = output.get('macro_indicators', {})
        
        # Key indicators
        key_indicators = ['VIX', 'SPY', 'QQQ', '10Y_Yield', 'GOLD', 'BTC']
        for ind in key_indicators:
            if ind in data:
                d = data[ind]
                val = d.get('value', 'N/A')
                chg = d.get('change_1d', 0)
                emoji = "ğŸŸ¢" if chg > 0 else "ğŸ”´" if chg < 0 else "âšª"
                print(f"   {emoji} {ind}: {val} ({chg:+.2f}%)")
        
        # Fear & Greed
        if 'FearGreed' in data:
            fg = data['FearGreed']
            print(f"\n   ğŸ’­ Fear & Greed: {fg.get('value')} ({fg.get('label', 'N/A')})")
        
        # AI Summary (first 500 chars)
        ai = output.get('ai_analysis', {})
        if isinstance(ai, dict):
            analysis = ai.get('ko', ai.get('en', ''))
        else:
            analysis = str(ai)
            
        if analysis:
            print(f"\nğŸ¤– AI Analysis Preview:")
            print(f"   {analysis[:500]}...")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Macro Market Analyzer')
    parser.add_argument('--dir', default='.', help='Data directory')
    parser.add_argument('--lang', default='ko', choices=['ko', 'en'], help='Output language')
    args = parser.parse_args()
    
    analyzer = MultiModelAnalyzer(data_dir=args.dir)
    output = analyzer.run()
    analyzer.print_summary(output)


if __name__ == "__main__":
    main()
